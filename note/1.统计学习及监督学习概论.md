# 统计学习及监督学习概论

## 1. 统计学习

### 1.1 统计学习的特点

> 统计学习(statistical learning) 是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。统计学习也称为统计机器学习

统计学习的主要特点

1. 统计学习以计算机及网络为平台，是建立在计算机及网络上的
2. 统计学习是以数据为研究回想，是以数据驱动的学科
3. 统计学习的目的是对数据进行预测于分析
4. 统计学习以方法为中心，统计学习方法构建模型井应用模型进行预测与分析
5. 统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独自的理论体系与方法论。

机器学习中"学习"的定义为：
> 赫尔伯特· 西蒙(Herbert A. Simon) 曾对"学习"给出以下定义: "如果一个系统能够通过执行某个过程改进它的性能，这就是学习。"

**统计学习就是计算机系统通过运用数据及统计方法提高系统性能的机器学习。**

### 1.2 统计学习的对象

统计学习研究的对象是**数据**。

统计学习从数据出发，提取数据的特征，抽象出数据的模型，发现数据中的知识，又回到对数据的分析与预测中去。作为统计学习的对象，数据是多样的，包括存在于计算机及网络上的各种数字、文字、图像、视频、音频数据以及它们的组合。

统计学习关于数据的基本假设是**同类数据具有一定的统计规律性，这是统计学习的前提**。

### 1.3 统计学习的目的

**统计学习用于对数据的预测与分析，特别是对未知新数据的预测与分析。**对数据的预测可以使计算机更加智能化，或者说使计算机的某些性能得到提高;对数据的分析可以让人们获取新的知识，给人们带来新的发现。

**对数据的预测与分析是通过构建概率统计模型实现的。**统计学习总的目标就是考虑学习什么样的模型和如何学习模型，以使模型能对数据进行准确的预测与分析，同时也要考虑尽可能地提高学习效率。

### 1.4 统计学习的方法

**统计学习的方法是基于数据构建概率统计模型从而对数据进行预测与分析。**
统计学习由监督学习(`supervised learning`) 、无监督学习(`unsupervised learning`) 和强化学习(`reinforcement learning`) 等组成。

> 监督学习和无监督学习是最重要的机器学习方法

统计学习方法可以概括为：

从给定的、有限的、用于学习的训练数据集合出发，假设数据是独立同分布产生的；
并且假设要学习的模型属于某个函数的集合，称为**假设空间(hypothesis space)**;
运用某种**评价准则(evealution criterion)**,从**假设空间**中选取一个最优模型，使它对己知的训练数据及未知的**测试数据(test data)** 在给定的**评价准则**下有最优的预测:最优模型的选取由算法实现。这样，统计学习方法包括模型的**假设空间、模型选择的准则以及模型学习的算法**。
称其为统计学习方法的三要素，简称为**模型(model)**、**策略(strategy)** 和 **算法(algorithm)**。

实现统计学习方法的步骤如下：

1. 得到一个有限的训练、数据集合
2. 确定包含所有可能的模型的假设空间，即学习模型的集合;
3. 确定模型选择的准则，即学习的策略;
4. 实现求解最优模型的算法，即学习的算法:
5. 通过学习方法选择最优模型:
6. 利用学习的最优模型对新数据进行预测或分析。

### 1.5 统计学习的研究

统计学习研究一般包括：
   **统计学习方法、统计学习理论及统计学习应用**三个方面

统计学习方法的研究旨在开发新的学习方法
统计学习理论的研究在于探求统计学习方法的有效性与效率，以及统计学习的基本理论问题
统计学习应用的研究主要考虑将统计学习方法应用到实际问题中去，解决实际问题。

## 2. 统计学习的分类

### 2.1 基本分类

> 统计学习或机器学习一般包括**监督学习**、**无监督学习**、**强化学习**。有时还包括**半监督学习**、**主动学习**。

#### 2.1.1 监督学习

监督学习(supervised learning) 是指从标注数据中学习预测模型的机器学习问题。标注数据表示输入输出的对应关系，预测模型对给定的输入产生相应的输出。

**监督学习的本质是学习输入到输出的映射的统计规律。**

**(1) 输入空间、特征空间和输出空间**：

在监督学习中，将输入与输出所有可能取值的集合分别称**为输入空间(input space)** 与**输出空间(output space)** 。**输入与输出空间可以是有限元素的集合，也可以是整个欧氏空间。输入空间与输出空间可以是同一个空间，也可以是不同的空间;*但通常输出空间远远小于输入空间。***

每个具体的输入是一个**实例(instance)** ，通常由**特征向量(feature vector)** 表示。这时，**所有特征向量存在的空间称为特征空间(feature space)**。特征空间的每一维对应于一个特征。有时假设输入空间与特征空间为相同的空间，对它们不予区分；**有时假设输入空间与特征空间为不同的空间，将实例从输入空间映射到特征空间。** *模型实际上都是定义在特征空间上的*。

在监督学习中，**将输入与输出看作是定义在输入(特征〉空间与输出空间上的随机变量的取值。**
输入输出变量用大写字母表示，习惯上输入变量写作$X$ ， 输出变量写作$Y$。输入输出变量的取值用小写字母表示，输入变量的取值写作$x$ ， 输出变量的取值写作$y$。变量可以是标量或向量，都用相同类型字母表示.
输入向量一般为列向量
$$x = (x^{(1)},x^{(2)},···,x^{(i)}),···,x^{(n)})^T$$

$x^{(i)}$表示$x$的第$i$个特征，而$x_i$通常表示输入变量中的第$i$个变量：

$$x_i = (x^{(1)}_i,x^{(2)}_i,···,x^{(n)}_i)^T$$

监督学习从训练数据(training data) 集合中学习模型，对测试数据(test data)进行预测。训练数据由输入(或特征向量)与输出对组成，训练集通常表示为:
$$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$$
**测试数据也由输入与输出对组成c 输入与输出对又称为样本(sample) 或样本点。**

输入变量X 和输出变量Y 有不同的类型，可以是连续的，也可以是离散的。人们根据输入输出变量的不同类型，对预测任务给予不同的名称
输入变量与输出变量均为连续变量的预测问题称为回归问题
输出变量为有限个离散变量的预测问题称为分类问题
输入变量与输出变量均为变量序列的预测问题称为标注问题。

**(3) 联合概率分布**：

监督学习假设输入与输出的随机变量$X$和$Y$遵循联合概率分布$P(X,Y)$。$P(X,Y)$表示分布函数或者分布密度函数。**注意在学习过程中，假定这一联合概率分布存在，但对学习系统来说，联合概率分布的具体定义是未知的。训练数据与测试数据被看作是依联合概率分布$P(X,Y)$独立同分布产生的。 统计学习假设数据存在一定的统计规律， $X$和$Y$ 具有联合概率分布就是监督学习关于数据的基本假设。**

**(3)假设空间**：
**监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。** 换句话说，学习的目的就在于找到最好的这样的模型。**模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间(hypothesis space) 。假设空间的确定意味着学习的范围的确定。**
监督学习的模型可以是概率模型和非概率模型，由条件概率分布$P(Y|X))$或决策函数(decision function)$Y=f(X)$表示,随具体学习方法而定。对具体的输入进行相应的输出预测时,写作$P(y|x)$或$y=f(x)$

**(4) 问题的形式化**：

监督学习利用训练数据集学习一个模型，再用模型对测试样本集进行预测。由于在这个过程中需要标注的训练数据集，而标注的训练数据集往往是人工给出的，所以称为监督学习。监督学习分为学习和预测两个过程，由学习系统与预测系统完成。
<center> 
<img src="https://z3.ax1x.com/2021/06/19/R9zX1U.jpg">
</center>

首先给定一个训练集

$$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$$

其中$(x_i,y_i), i=1,2,...,N$称为样本或样本点。$x_i\in\mathcal{X}\subseteq R^n$是输入的观测值，也成为输入或者示例，$y_i\in \mathcal{Y}$是输出的观测值也成为输出。
**监督学习分为学习和预测两个过程**，由学习系统与预测系统完成。在学习过程中，学习系统利用给定的训练数据集，通过学习(或训练)得到一个模型，表示为条件概率分布$\^{P}(Y|X)$或决策函数$Y=\hat{f}(X)$。条件概率分布件$\^{P}(Y|X)$或决策函数$Y=\hat{f}(X)$描述输入与输出随机变量之间的映射关系。在预测过程中，预测系统对于给定的测试样本集中的输入$x_{N+1}$由模型$y_{N+1}=\underset{y}{\argmax\hat{P}(y|x_{N+1})}$或$y_{N+1}=\hat{f}(x_{N+1})$给出相应的输出$y_{N+1}$

学习系统(也就是学习算法)试图通过训练数据集中的样本$(X_i,Y_i)$带来的信息学习模型。具体地说，对输入叭，一个具体的模型$y = f(x)$可以产生一个输出$f(x_i)$,而训练数据集中对应的输出是$y_i$。如果这个模型有很好的预测能力，训练样本输出$y_i$和模型输出$f(x_i)$之间的差就应该足够小。学习系统通过不断地尝试，选取最好的模型，以便对训练数据集有足够好的预测，同时对未知的测试数据集的预测也有尽可能好的推广。

#### 2.1.2 无监督学习

无监督学习(unsupervised learning) 是指从无标注数据中学习预测模型的机器学习问题。无标注数据是自然得到的数据，预测模型表示数据的类别、转换或概率。**无监督学习的本质是学习数据中的统计规律或潜在结构**。

模型的输入与输出的所有可能取值的集合分别称为输入空间与输出空间。输入空间与输出空间可以是有限元素集合，也可以是欧氏空间。每个输入是一个实例，由特征向量表示。每一个输出是对输入的分析结果，由输入的类别、转换或概率表示。模型可以实现对数据的聚类、降维或概率估计。

假设$\mathcal{X}$是输入空间，$\mathcal{Z}$是隐式结构空间。要学习的模型可以表示为$z=g(x)$,条件概率分布$P(z|x)$,或者条件概率分布$P(x|z)$的形式,其中$x \in \mathcal{X}$是输入，$z \in \mathcal{Z}$是输出。包含所有可能的模型的集合称为假设空间。无监督学习旨在从假设空间中选出在给定评价标准下的最优模型。

无监督学习通常使用大量的无标注数据学习或训练，每一个样本是一个实例。训练数据表示为$U=\{x_1,x_2,...,x_{\small{N}}\},i=1,2,...,N$
无监督学习可以用于对己有数据的分析，也可以用于对未来数据的预测。分析时使用学习得到的模型,即函数$z=\^{g}(x)$,条件概率$\^{P}(z|x)$或者$\^{P}(x|z)$.
预测时，和监督学习有类似的流程。由学习系统与预测系统完成，如图所示。在学习过程中，学习系统从训练数据集学习，得到一个最优模型，表示为$z=\^{g}(x)$,条件概率分布$\^{P}(z|x)$或者$\^{P}(x|z)$，在预测过程中系统对于给定的输入$x_{N+1}$，由模型$z_{N+1}=\^{g}(x_{N+1})或z_{N+1}=\underset{z}{\argmax}\^{P}(z|x_{N+1})$给出相应的输出$z_{N+1}$，进行聚类或降维，亦或是由模型$\^{P}(x|z)$给出输入的概率$\^{P}(x_{N+1}|z_{N+1})$进行概率估计
<center>
   <img src="https://z3.ax1x.com/2021/06/19/RCMcAx.jpg">
</center>

#### 2.1.3 强化学习

强化学习(reinforcement learning) 是指智能系统在与环境的连续互动中学习最优行为策略的机器学习问题。假设智能系统与环境的互动基于马尔可夫决策过程(Markov decision process) ，智能系统能观测到的是与环境互动得到的数据序列。**强化学习的本质是学习最优的序贯决策。**
<center><img src="https://z3.ax1x.com/2021/06/19/RCQXIx.jpg"></center>

智能系统与环境的互动如图所示。在每一步$t$,智能系统从环境中观测到一个状态(state) $s_t$ 与一个奖励(reward)$r_t$,采取一个动作(action)$a_t$。画家更具智能系统选择的动作，决定下一步$t+1$的状态$s_{t+1}$与奖励$r_{t+1}$.
要学习的策略表示为给定的状态下采取的动作。智能系统的目标不是短期奖励的最大化，而是长期累积奖励的最大化。强化学习过程中，系统不断地试错(trial and error) ，以达到学习最优策略的目的。

强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程，由五元组$\langle S,A,P,r,\gamma\rangle$组成。

- S是有限状态(state)的集合
- A是有限动作(action)的集合
- P是状态转移概率(transition probability)函数：$$P(s'|s,a)=P(s_{t+1}=s||s_t=s,a_t=a)$$
- r是奖励函数(reward function): $r(s,a) = E(r_{t+1}|s_t=s, a_t=a)$
- $\gamma$是衰减系数：$\gamma \in [0,1]$

马尔可夫决策过程具有马尔可夫性，下一个状态只依赖于前一个状态与动作，由状态转移概率函数$P(s'|s,a)$下一个奖励依赖于前一个状态与动作，由奖励函数$r(s,a)$表示。
策略$\pi$定义为给定状态下的动作函数$a=f(s)$或者条件分布概率$P(a|s)$。给定一个策略$\pi$，智能系统与缓解互动的行为就已经确定(或者是确定性的或者是随机性的)
价值函数(value function)或者状态价值函数(state value function)定义为策略$\pi$从某一个状态$s$开始的长期累积的数学期望：
$$v_\pi(s)=E_\pi[r_{t+1}+\gamma r_{t+2}+\gamma^2r_{t+3}+...|s_t=s]$$
动作价值函数(action value function) 定义为策略汀的从某一个状态$s$和动作$a$开始的长期累积奖励的数学期望:
$$q_\pi(s,a)=E_\pi[r_{t+1}+\gamma r_{t+2}+\gamma^2 r_{t+3}+...|s_t=s,a_t=a]$$
强化学习的目标就是在所有可能的策略中选出价值函数最大的策略$\pi^*$而在实际学习中往往从具体的策略出发，不断优化己有策略。这里$\gamma$表示未来的奖励会有衰减。

强化学习方法中有基于策略的(policy-based) 、基于价值的(value-based) ，这两者属于无模型的(model-free) 方法，还有有模型的(model-based) 方法。

有模型的方法试图直接学习马尔可夫决策过程的模型，包括转移概率函数$P(s'|s,a)$和奖励函数$r(s,a)$ 。这样可以通过模型对环境的反馈进行预测，求出价值函数最大的策略$\pi^*$

无模型的、基于策略的方法不直接学习模型，而是试图求解最优策略$\pi^*$表示为函数$a=f^*(s)$ 或者是条件概率分布$P*(a|s)$ ，这样也能达到在环境中做出最优决策的目的。学习通常从一个具体策略开始，通过搜索更优的策略进行。
无模型的、基于价值的方法也不直接学习模型，而是试图求解最优价值函数，特别是最优动作价值函数$q*(s,a)$。这样可以间接地学到最优策略，根据该策略在给定的状态下做出相应的动作。学习通常从一个具体价值函数开始，通过搜索更优的价值函数进行。


### 2.2 按模型分类

#### 2.2.1 概率模型和非概率模型

统计学习模型分为概率模型，非概率模型(确定性模型)。在监督学习中，概率模型取条件概率分布形式$P(y|x)$，非概率模型取函数形式$y=f(x)$。在无监督学习中，概率模型取条件概率分布形式$P(x|z)$ 或$P(z|x)$,非概率模型取函数形式$z=g(x)$。

> 在监督学习中，概率模型是监督模型，非概率模型是判别模型

常见的概率模型：

- 决策树
- 朴素贝叶斯
- 隐马尔可夫模型
- 条件随机场
- 概率潜在语义分析
- 潜在狄利克雷分配
- 高斯混合模型

常见的非概率模型：

- 感知机
- 支持向量机
- k 近邻
- AdaBoost
- k 均值
- 潜在语义分析
- 神经网络

> 特例：逻辑斯谛回归
> 既可以看作概率模型也可以看作是非概率模型

对于概率模型，条件分布概率$P(y|x)$和函数$y=f(x)$可以互相转换，对于无监督学习亦是如此。
条件概率分布最大化后得到函数，函数归一化后得到条件概率分布。
概率模型和非概率模型的区别不在于输入与输出之间的映射关系，而在于模型的内在结构。**概率模型一定可以表示为联合概率分布的形式，其中的变量表示输入、输出、隐变量甚至参数。而针对非概率模型则不一定存在这样的联合概率分布。**

概率模型的代表是概率图模型(probabilistic graphical model) ，**概率图模型是联合概率分布由有向图或者无向图表示的概率模型，而联合概率分布可以根据图的结构分解为因子乘积的形式。** 贝叶斯网络、马尔可夫随机场、条件随机场是概率图模型。无论模型如何复杂，均可以用最基本的加法规则和乘法规则 进行概率推理。

$$
\begin{aligned}
   加法规则: &&P(x)=\sum_xP(x,y) \\
   乘法规则: &&P(x,y)=P(x)P(y|x)
\end{aligned}
$$

其中x,y是随机变量

#### 2.2.2 线性模型和非线性模型

统计学习模型，特别是非概率模型，可以分为线性模型(linear model) 和非线性模型(non-linear model) 。如果函数$y = f(x)$ 或$z = g(x)$ 是线性函数，则称模型是线性模型，否则称模型是非线性模型。
常见的线性模型：

- 感知机
- 线性支持向量机
- k 近邻
- k 均值
- 潜在语义分析
  
常见的非线性模型

- 核函数支持向量机
- AdaBoost
- 神经网络

#### 2.2.3 参数化模型和非参数化模型

统计学习模型又可以分为参数化模型(parametric model)和非参数化模型(nonparametric model) 。**参数化模型假设模型参数的维度固定，模型可以由有限维参数完全刻画；非参数化模型假设模型参数的维度不固定或者说无穷大，随着训练数据量的增加而不断增大。**

常见的参数化模型：

- 感知机
- 朴素贝叶斯
- 逻辑斯谛回归
- k 均值
- 高斯混合模型

非参数化模型：

- 决策树
- 支持向量机
- AdaBoost 
- k 近邻
- 潜在语义分析
- 概率潜在语义分析
- 潜在狄利克雷分配

**参数化模型适合问题简单的情况，现实中问题往往比较复杂，非参数化模型更加有效。**

### 2.3 按技巧分类

#### 2.3.1 贝叶斯学习

贝叶斯学习(Bayesian learning) ，又称为贝叶斯推理(Bayesian inference) ，是统计学、机器学习中重要的方法。其主要想法是，在概率模型的学习和推理中，利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率，并应用这个原理进行模型的估计，以及对数据的预测。将模型、未观测要素及其参数用变量表示，**使用模型的先验分布是贝叶斯学习的特点。贝叶斯学习中也使用基本概率公式**

> 朴素贝叶斯、潜在狄利克雷分配的学习属于贝叶斯学习

假设随机变量$D$表示数据，随机变量$\theta$表示模型参数。根据贝叶斯定理，可以用如下公式计算后验概率$P(\theta|D)$:
$$P(\theta|D)=\frac{P(\theta)P(D|\theta)}{P(D)}$$
$P(D)$是先验概率，$P(D|\theta)$是似然函数

模型估计时，估计整个后验概率分布$P(\theta|D)$如果需要给出一个模型，通常取后验概率最大的模型。
预测时，计算数据对后验概率分布的期望值:
$$P(x|D)=\int P(x|\theta,d)P(\theta|D)d\theta$$
$x$是新样本。
贝叶斯估计与极大似然估计在思想上有很大的不同，代表着统计学中频率学派和贝叶斯学派对统计的不同认识。其实，可以简单地把两者联系起来，假设先验分布是均匀分布，取后验概率最大，就能从贝叶斯估计得到极大似然估计。

<center>
   <img src="https://z3.ax1x.com/2021/06/19/RPecmq.jpg">
</center>

#### 2.3.2 核方法

**核方法(kernel method) 是使用核函数表示和学习非线性模型的一种机器学习方法，可以用于监督学习和无监督学习。**有一些线性模型的学习方法基于相似度计算，更具体地，向量内积计算。核方法可以把它们扩展到非线性模型的学习，使其应用范围更广泛。
常见的的核方法包括:

- 支持向量机
- 核PCA
- 核k均值
  
把线性模型扩展到非线性模型，直接的做法是显式地定义从输入空间(低维空间)
到特征空间(高维空间)的映射，在特征空间中进行内积计算。比如，支持向量机，把输入空间的线性不可分问题转化为特征空间的线性可分问题，如图1.7 所示。核方法的技巧在于不显式地定义这个映射，而是直接定义核函数，即映射之后在特征空间的内积。这样可以简化计算，达到同样的效果。

<center>
   <img src="https://z3.ax1x.com/2021/07/03/RgyZrt.jpg">
</center>

$x_1,x_2$,是输入空间的任意两个实例（向量），其内积是$\langle x_1,x_2 \rangle$,假设输入控件到特征空间的映射是$\varphi$,于是$x_1,x_2$在特征空间的映像是$\varphi(x_1), \varphi(x_2)$，其内积是$\langle \varphi(x_1), \varphi(x_2) \rangle$,核方法直接在输入空间中定义核函数$K(x_1, x_2)$，使其满足$K(x_1, x_2) = \langle \varphi(x_1), \varphi(x_2) \rangle$,表示定理给出核函数技巧成立的充要条件。

## 3. 统计学习方法三要素

$$方法 = 模型+策略+算法$$

统计学习方法都是由模型、策略和算法构成的，即统计学习方法由三要素构成。非监督学习、强化学习也同样拥有这三要素。可以说构建一种统计学习方法就是确定具体的统计学习三要素。

### 3.1 模型

**统计学习首要考虑的问题是学习什么样的模型**。例如，在监督学习过程中模型就是所要学习的条件概率分布或决策函数。模型的假设空间(hypothesis space) 包含所有可能的条件概率分布或决策函数。例如，假设决策函数是输入变量的线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合。假设空间中的模型一般有无穷多个。

假设空间用$\mathcal{F}$表示，。假设空间可以定义为决策函数的集合：

$$
   \mathcal{F} = \{f|Y=f(X)\}
$$
其中$X,Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的变量。这时$\mathcal{F}$是由一个参数向量决定的函数族：

$$
   \mathcal{F} = \{f|Y=f_{\theta}(X), \theta \in \mathbf{R}^n\}
$$

参数向量$\theta$取值于$n$维欧式空间$\mathbf{R}^n$，称为参数空间（parameter space）。
假设空间也可以定义为条件概率的集合:
$$\mathcal{F}=\{P|P(Y|X)\}$$
其中，$X,Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的随机变量。这时$\mathcal{F}$通常是由一个参数向量巨鼎的条件概率分布族：
$$\mathcal{F}=\{P|P_{\theta}(Y|X)\,\theta \in \mathbf{R}^n \}$$

### 3.2 策略

> 有了模型的假设空间，统计学习接着需要考虑的是按照什么样的准则学习或选择最优的模型。统计学习的目标在于从假设空间中选取最优模型

#### 3.2.1 损失函数和风险函数

监督学习问题是在假设空间$\mathcal{F}$中选取模型$f$作为决策函数，对于给定的输入$X$,由$f(X)$给出相应的输出$Y$,这个输出的预测值$f(X)$于真实值$Y$可能一致也可能不一致，用一个损失函数(loss function)或代价函数(cost function)来度量预测错误的程度。损失函数是$f(X)$和$Y$的非负实值函数，记作$L(Y,f(X))$

统计学习常用的损失函数：

**(1) 0-1 损失函数(0-1 loss function)**:

$$
L(Y,f(X)) = \begin{cases}
1, Y \not ={f(X)} \\
0, Y=f(X)
\end{cases}
$$

**(2) 平方损失函数(quadratic loss function):**

$$
L(Y,f(X)) = (Y-f(X))^2
$$

**(3)绝对损失函数(absolute loss function):**
$$
L(Y,f(X)) = |Y-f(X)|
$$

**(4)对数损失函数(logarithmic loss function):**
$$L(Y,P(Y|X))=-\log P(Y|X)$$

损失函数值越小，模型就越好。由于模型的输入、输出$(X，Y)$是随机变量，遵循联合分布$P(X， Y)$,所以损失函数的期望是:

$$
\begin{aligned}
R_{exp}(f) & = E_p[L(Y,f(x))]\\
 & = \int_{\mathcal{X}\times\mathcal{Y}} L(y,f(x))P(x,y)dxdy
\end{aligned}
$$
这是理论上模型$f(X)$关于联合分布$P(X,Y)$的平均意义的损失，称为风险函数(risk function)或者期望损失(expected loss)

学习的目标就是选择期望风险最小的模型.由于联合概率$P(X,Y)$未知，所以$R_{exp}(f)$不能直接计算。

给定一个训练集
$$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$$
模型$f(X)$关于训练集的平均损失称为经验风险(empirical risk)或经验损失(empirical loss),记作$R_{emp}$:

$$
R_{emp} = \frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i))
$$

$R_{exp}$是关于联合概率分布的期望损失，而经验风险$R_{emp}$是模型关于训练样本的平均损失。当样本容量$N$趋于无穷时，经验风险$R_{emp}$趋于期望风险$R_{exp}$

所以一个很自然的想法是用经验风险估计期望风险。但是，由于现实中训练样本数目有限，甚至很小，所以用经验风险估计期望风险常常井不理想，要对经验风险进行一定的矫正。**这就关系到监督学习的两个基本策略: 经验风险最小化和结构风险最小化。**

#### 3.2.2 经验风险最小化于结构化风险最小

在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定。经验风险最小化(empirical risk minimization, ERM) 的策略认为，经验风险最小的模型是最优的模型。根据这一策略，按照经验风险最小化求最优模型就是求解最优化问题:

$$
\min_{f\in \mathcal{F}} \frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i))
$$

其中$\mathcal{F}$是假设空间
当样本容量足够大时，经验风险最小化能保证有很好的学习效果，在现实中被广泛采用比如，极大似然估计(maximum likelihood estimation) 就是经验风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计。

但是， 当样本容量很小时，经验风险最小化学习的效果就未必很好，会产生"过拟合" (over-fitting) 现象。

结构风险最小化(structural risk minimization, SRM) 是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化(regularization) 。结构风险在经验风险上加上表示模型复杂度的正则化项(regularizer)或罚项(penalty term) 。在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是:

$$
   R_{srm}(f)=\frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i)+\lambda J(f))
$$

其中$J(f)$是模型的复杂度，是定义在假设空间$\mathcal{F}$上的泛函。模型$f$越复杂，复杂度就越大复杂度表示了对复杂模型的惩罚。$\lambda \geq 0$是系数，用于权衡经验风险模型和模型复杂度。**结构风险小需要经验风险与模型复杂度同时小。结构风险小的模型往往对训练数据以及未知的测试数据都有较好的预测。**

比如，**贝叶斯估计中的最大后验概率估计(maximum posterior probability estimation,MAP)** 就是结构风险最小化的一个例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等价于最大后验概率估计。

结构风险最小化的策略认为结构风险最小的模型是最优的模型。所以求最优模型，就是求解最优化问题:

$$
   \min_{f\in\mathcal{F}}\frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i)+\lambda J(f))
$$

这样，监督学习问题就变成了经验风险或结构风险函数的最优化问题 。这时经验或结构风险函数是最优化的目标函数。

### 3.3 算法

算法是指学习模型的具体计算方法。统计学习基于训练数据集，根据学习策略，从假设空间中选择最优模型，最后需要考虑用什么样的计算方法求解最优模型。

这时，统计学习问题归结为最优化问题，统计学习的算法成为求解最优化问题的算法。如果最优化问题有显式的解析解，这个最优化问题就比较简单。但通常解析解不存在，这就需要用数值计算的方法求解。如何保证找到全局最优解，并使求解的过程非常高效，就成为一个重要问题。统计学习可以利用己有的最优化算法，有时也需要开发独自的最优化算法。

**统计学习方法之间的不同，主要来自其模型、策略、算法的不同。**确定了模型、策略、算法，统计学习的方法也就确定了。这就是将其称为统计学习方法三要素的原因。

## 4 模型评估与模型选择

### 4.1 训练误差与测试误差

统计学习的目的是使学到的模型不仅对己知数据而且对未知数据都能有很好的预测能力。不同的学习方法会给出不同的模型。当损失函数给定时，基于损失函数的模型的训练误差(training error) 和模型的测试误差(test error) 就自然成为学习方法评估的标准。

> 统计学习方法具体采用的损失函数未必是评估时使用的损失函数。当然，让两者一致是比较理想的。

假设学习到的模型是$Y=\^f(X)$，训练误差是模型$Y=\^f(X)$关于训练数据集的平均损失：
$$
R_{emp}(\^f)=\frac{1}{N}\sum^N_{i=1}L(y_i,\^f(x_i))
$$
N是训练样本容量

测试误差是模型关于测试集的平均损失：
$$
e_{test}=\frac{1}{N'}\sum^{N'}_{i=1}L(y_i,\^f(x_i))
$$
$N'$是测试集样本容量

当损失函数是0-1 损失时，测试误差就变成了常见的测试数据集上的误差率(error rate) :

$$
e_{test} = \frac{1}{N'}\sum^{N'}_{i=1}I(y_i \neq \^f(x_i))
$$
这里I 是指示函数(indicator function) ，即$y_i \neq \^f(x_i)$时为1，否则为0 。

相应的测试数据集上的准确率为：
$$
r_{test} =  \frac{1}{N'}\sum^{N'}_{i=1}I(y_i = \^f(x_i))
$$
显然
$$t_{test} + e_{test} = 1 $$

训练误差的大小，对判断给定的问题是不是一个容易学习的问题是有意义的，但本质上不重要。测试误差反映了学习方法对未知的测试数据集的预测能力，是学习中的重要概念。**显然，给定两种学习方法，测试误差小的方法具有更好的预测能力，是更有效的方法。**

### 4.2 过拟合与模型选择

当假设空间有不同的复杂度(例如，不同的参数个数)的模型时，就需要进行模型选择。如果假设空间中存在"真模型"，那么所选模型应该向真模型逼近。

如果一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高。这种现象称为过拟合(over-fitting) 。过拟合是指学习时选择的模型所包含的参数过多，以至出现这一模型对己知数据预测得很好，但对未知数据预测得很差的现象。可以说模型选择旨在避免过拟合并提高模型的预测能力。

当模型的复杂度增大时，训练误差会逐渐减小井趋向于0; 而测试误差会先减小，达到最小值后又增
大。当选择的模型复杂度过大时，过拟合现象就会发生。
<center>
<img src="https://z3.ax1x.com/2021/07/11/W9gPBV.jpg" alt="W9gPBV.jpg" border="0" />
</center>

在学习时就要防止过拟合，进行最优的模型选择，即选择复杂度适当的模型，以达到使测试误差最小的学习目的。下面介绍两种常用的模型选择方法:正则化与交叉验证。

## 5. 正则化与交叉验证

### 5.1 正则化

**模型选择的典型方法是正则化(regularization) 。正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项(regularizer )或罚(Cpenalty term) 。**正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如， 正则化项可以是模型参数向量的范数。

正则化一般具有如下形式：
$$
\min_{f\in\mathcal{F}}\frac{1}{N}\sum^N_{i=1}L(y_i,f(x_i)+\lambda J(f))
$$

其中，第1 项是经验风险，第2 项是正则化项， $\lambda \geq 0$为调整两者之间关系的系数。

正则化项可以取不同的形式。例如，在回归问题中，损失函数时平方损失，正则化向可以是参数向量的$L_2$范数：
$$
L(w) = \frac{1}{N}\sum^N_{i=1}(f(x_i,w)-y_i)^2 + \frac{\lambda}{2} \|w\|^2
$$

$\|w\|$表示参数向量$w$的$L_2$范数
正则化项也可以时参数向量的$L_1$范数

$$
L(w) = \frac{1}{N}\sum^N_{i=1}(f(x_i,w)-y_i)^2 + \frac{\lambda}{2} \|w\|_1
$$
$\|w\|_1$时参数向量$w$的$L_1$范数

第1 项的经验风险较小的模型可能较复杂(有多个非零参数)，这时第2 项的模型复杂度会较大。**正则化的作用是选择经验风险与模型复杂度同时较小的模型。**

### 5.2 交叉验证

如果给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分别为训练集(training set) 、验证集(validation set) 和测试集(test set) 。训练集用来训练模型，验证集用于模型的选择，而测试集用于最终对学习方法的评估。**在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。由于验证集有足够多的数据，用它对模型进行选择也是有效的。**

但是，在许多实际应用中数据是不充足的。为了选择好的模型，可以采用交叉验证方法。**交叉验证的基本想法是重复地使用数据;把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。**

1. 简单交叉验证
单交叉验证方法是:首先随机地将己给数据分为两部分， 一部分作为训练集，另一部分作为测试集(例如， 70% 的数据为训练集， 30% 的数据为测试集) ;然后用训练集在各种条件下(例如，不同的参数个数)训练模型，从而得到不同的模型:在测试集上评价各个模型的测试误差，选出测试误差最小的模型。

2. S折交叉验证
应用最多的是S 折交叉验证(S-fold cross validation) ，方法如下:首先随机地将已给数据切分为S 个互不相交、大小相同的子集;然后利用S-l 个子集的数据训练模型，利用余下的子集测试模型:将这一过程对可能的S 种选择重复进行;最后选出S 次评测中平均测试误差最小的模型。

3. 留一交叉验证
S 折交叉验证的特殊情形是S = N ， 称为留一交叉验证(leave-one-out cross validation) ，往往在数据缺乏的情况下使用。这里， N是给定数据集的容量。

## 6. 泛化能力

### 6.1 泛化误差

**学习方法的泛化能力(generalization ability) 是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。** 现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力。但这种评价是依赖于测试数据集的。因为测试数据集是有限的，很有可能由此得到的评价结果是不可靠的。统计学习理论试图从理论上对学习方法的泛化能力进行分析。

泛化误差的定义为，如果学到的模型$\^f$,用这个模型对未知数据预测的误差即为泛化误差：

$$
\begin{aligned}
   R_{exp}(\^f)&=E_P[L(Y,\^f(X))] \\
   &=\int_{\mathcal{X}\times\mathcal{Y}}L(y,\^f(x))P(x,y)dxdy
\end{aligned}
$$

**泛化误差反映了学习方法的泛化能力，如果二种方法学习的模型比另一种方法学习的模型具有更小的泛化误差，那么这种方法就更有效。事实上，泛化误差就是所学习到的模型的期望风险**。

### 6.2 泛化误差上界

学习方法的泛化能力分析往往是通过**研究泛化误差的概率上界**进行的，简称为泛化误差上界(generalization error bound) 。具体来说，就是通过比较两种学习方法的泛化误差上界的大小来比较它们的优劣。**泛化误差上界通常具有以下性质:它是样本容量的函数，当样本容量增加时，泛化上界趋于0; 它是假设空间容量(capacity) 的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大。**

下面给出一个简单的泛化误差上界的例子: 二类分类问题的泛化误差上界。

考虑二类分类问题。已知训练数据集$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$,$N$是样本容量， T 是从联合概率分布$P(X， Y)$独立同分布产生的， $X\in R^n, Y\in \{-1,+1\}$。假设空间是函数的有限集合$\mathcal{F}=\{f_1,f_2,...,f_d\},d$是函数个数。设$f$是从$\mathcal{F}$中选取的函数。损失函数是0-1 损失。关于f 的期望风险和经验风险分别是

$$
R(f) = E[L(Y,f(X))]
$$

$$\^R(F)=\frac{1}{N}\sum_{i=1}^NL(y_i,f(x_i))$$

经验风险最小化函数是
$$f_N=\arg\min_{f \in \mathcal{F}}\^R(f)$$

$f_N$ 依赖训练集的样本容量 $N$ ,泛化误差为
$$R(f_N)=E[L(Y,f_N(X))]$$

在有限集合$\mathcal{F}=\{f_1,f_2,...,f_d\}$中任意选出的函数$f$的泛化误差上界

#### **泛化误差上界定理**

对于二分类问题，当假设空间是有限个函数的集合$\mathcal{F}=\{f_1,f_2,...,f_d\}$时，对任意一个函数$f\in\mathcal{F}$,至少以概率$1-\delta, 0<\delta<1$,以下不等式成立
$$R(f) \leq \^R(f) + \varepsilon(d,N,\delta)$$

其中，
$$\varepsilon(d,N,\delta)=\sqrt{\frac{1}{2N}(\log d+\log\frac{1}{\delta})}$$

在不等式中$R(f)$是泛化误差，右端就是泛化误差上界，第一项是训练误差，训练误差越小泛化误差就越小。第二项$\varepsilon(d,N,\delta)$是$N$的单调递减函数，$N$趋于无穷时趋于0，同时他也是$\sqrt{\log d}$阶的函数，假设空间$\mathcal{F}$包含的函数越多，其值越大

## 7.生成模型和判别模型

监督学习的任务就是学习一个模型，应用这一模型，对给定的输入预测相应的输出。这个模型的一般形式为决策函数:

$$Y=f(X)$$

或者条件概率分布
$$P(Y|X)$$

监督学习方法又可以分为生成方法(generative approach) 和判别方法(discriminativeapproach) 。所学到的模型分别称为生成模型(generative model)和判别模型(discriminative model) 。

生成方法由数据学习联合概率分布$P(X， Y)$ ， 然后求出条件概率分布$P(Y|X)$作为预测的模型，即生成模型:

$$
P(Y|X)=\frac{P(X,Y)}{P(X)}
$$
这样的方法之所以称为生成方法，是因为模型表示了给定输入X 产生输出Y 的生成关系。典**型的生成模型有朴素贝叶斯法和隐马尔可夫模型**

